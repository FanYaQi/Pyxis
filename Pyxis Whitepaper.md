A key factor in developing Pyxis is designing for extensibility and continual improvement by adding new data. The Pyxis system workflow follows a sequence of steps when new data is entered: (1) Standardize, (2) Match, (3) Estimate, and (4) Update, as shown in Figure 1. The Pyxis system first cleans the new or unknown input field data and standardizes it to mediate data schema suitable for data mapping and querying. In the second step, the Pyxis data pipeline matches the input data with existing records in the Pyxis database based on a flexible match algorithm (specified in section 2.2.3). Third, if no match is found, Pyxis will provide the enriched estimated data (e.g., by calculating the neighbor/region average) and use the new record to update the database depending on the input data quality. Enriched estimated data refers to processed field data that combines the original data and the matched field data from the database, and they can be used for GHG emission estimation using the LCA model like OPGEE. The CI results generated are visualized and reported through dashboards. Fourth, the enriched data, if validated, is used to update the Pyxis database, ensuring continuous improvement. 

Specifically, The database initialization begins with two key steps: standardize and match. During standardization, the system first evaluates each data source using the data score algorithm and then generates a source metadata table(human generated for now) and a source information table(input). A unique schema mapping from each source schema to the mediated schema, specifically Pyxis schema, is needed for the detailed source information table and is documented in the configuration files. Next, the system prioritizes data sources based on their quality scores and starts matching. Pyxis begins by using the highest-quality source to create the initial Pyxis match table, assigning a match score 100. It then matches fields from the second-highest quality source to this table, calculating match scores using the algorithm. If a new field doesn't find a match in the Pyxis match table, it is added as a new entry with an initial match score of 100. This process continues iteratively until all initial datasets are integrated into the Pyxis match table.

Once the database is initialized, the system processes new data in two steps: ingest and merge. For ingestion, whether the data comes in bulk from a third party or in smaller pieces from literature, it undergoes standardization and matching like above. A data quality assessment during standardization determines whether the new data meets the threshold for integration into the Pyxis database. If the data doesn't meet the threshold, it is stored in unstructured JSON format, and the system will provide the matching results without updating it. If it does meet the threshold, it will undergo an extra step of merging. Specifically, the input field data will be first integrated into the Pyxis match table using the same process described earlier. Then, the system updates the Pyxis merge table using the merge algorithm, formatting it into emission model input columns for estimation.

Through these four steps, the Pyxis system effectively integrates large datasets and incorporates scattered information from user inputs and literature, ensuring a thorough system implementation.


For example for my paper's case study country Brazil, To construct the Pyxis geodatabase for Brazil, the four data sources were first standardized to form the source metadata and source information tables. Semantic mappings were created between each data source's original schema and Pyxis's target-mediated schema based on their available data dictionaries. For simplification, the target-mediated schema for Pyxis was defined to match the primary data schema for OPGEE, which contains 65 fields of field information. After the data quality assessment, the sources were ranked as ANP, CD, GOGI, and Zhang, from highest to lowest. 

Given the data quality rank, we then sequentially match these data sources to build the first version of the Pyxis database. The matching algorithm relies on name and geolocation matching, facilitated by introducing the spatial operations in H3. By indexing each field's centroid using H3 cells, the geolocation match score was easily calculated based on the number of cells between two centroids. Following this flow, ANP's fields were formatted into the initial Pyxis match table. Subsequently, CD's fields were matched to the Pyxis match table. Pyxis calculated each CD fieldâ€™s match scores with all existing Pyxis fields, selected the highest-scoring match, and then added CD fields to the Pyxis match table. In rare cases of equally scored matches, priority was given to the one with a higher name match score, as centroid geolocation can sometimes be misleading. The stringent geolocation score helped prevent matching far-away fields that happen to have the same name. After matching all data sources through three iterations, the initial Pyxis database for Brazil's fields was constructed.

As an example, we ingest 12 literature papers to explore pipeline construction built upon the existing database. As depicted in the implementation flowchart in Figure 4, data from new sources undergo a standardization and matching process similar to existing data. If the paper source meets the data quality score threshold, the system will integrate its information into the database. Otherwise, the system will not update the database and will provide field data estimates with the existing database. Unstructured data from sources not meeting the quality score are stored in JSON files for future reference, for example, if future database versions would be willing to have sources with lower quality scores.

After ingesting and merging the source field information for oilfield operations parameters, the system integrates real-time satellite data for CI estimation. In this case study, satellite flaring data from the VIIRS for Brazil are assigned to the Pyxis fields, following a methodology similar to Zhang et al. However, in this case, we use the H3 boundaries generated by the Pyxis system. Flares are matched to fields by verifying if they fall within the H3 cell clusters and then aggregating flare volumes. For overlapping fields, allocation is based on production data. This initial flare matching captures 96.97% of flares in Brazil. To account for the fact that some flares may lie outside the formal H3 boundaries, we create an alternative algorithm incorporating a 5 km buffer around the H3 shape. This step captures 2.24% more flares. After these steps, only 0.79% of flares remain unmatched by an existing field shape in Pyxis.

The final output should be the Pyxis field with its OPGEE input. The sequence of my main code would be data_processing/data_standardization -> get_pyxis_match_table -> get_pyxis_merge_info -> get_pyxis_merge_info_with_flare.py -> get_OPGEE_prepared.py, and the internal files like source info table, meta table, match table, etc should be stored in the database.